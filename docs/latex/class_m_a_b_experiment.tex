\hypertarget{class_m_a_b_experiment}{}\section{M\+A\+B\+Experiment Class Reference}
\label{class_m_a_b_experiment}\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}


In order to test different algorithms with the same data, they must be able to obtain the same reward when pulling an arm in the same timestep. The \mbox{\hyperlink{class_m_a_b_experiment}{M\+A\+B\+Experiment}} class generate all the rewards of the arms up to the time horizon, before the algorithm starts.  




{\ttfamily \#include $<$mab.\+h$>$}



Inheritance diagram for M\+A\+B\+Experiment\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=151pt]{class_m_a_b_experiment__inherit__graph}
\end{center}
\end{figure}


Collaboration diagram for M\+A\+B\+Experiment\+:
\nopagebreak
\begin{figure}[H]
\begin{center}
\leavevmode
\includegraphics[width=151pt]{class_m_a_b_experiment__coll__graph}
\end{center}
\end{figure}
\subsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\hyperlink{class_m_a_b_experiment_a1f24b5ccad7521d47a7f4c3961867063}{M\+A\+B\+Experiment}} (vector$<$ \mbox{\hyperlink{class_distribution}{Distribution}} $\ast$$>$ \&\mbox{\hyperlink{class_m_a_b_experiment_abcea657cec661467e38422059dbd4a2d}{arms}})
\item 
vector$<$ vector$<$ double $>$ $>$ \mbox{\hyperlink{class_m_a_b_experiment_af31d09524129608838d5262678e8de18}{generate\+\_\+pulls}} (int timesteps)
\begin{DoxyCompactList}\small\item\em Generate the pulls for each arm up to the specified time horizon. \end{DoxyCompactList}\item 
vector$<$ int $>$ \mbox{\hyperlink{class_m_a_b_experiment_af64386f9138dcd31873d9218b7adf6fb}{get\+\_\+available\+\_\+actions}} () override
\item 
double \mbox{\hyperlink{class_m_a_b_experiment_acf2ca557df3d30325d8ff180c223a54a}{observe\+\_\+reward}} (int action) override
\item 
void \mbox{\hyperlink{class_m_a_b_experiment_a0159e6c16372d282c0e2afd711da22c8}{next\+\_\+step}} ()
\begin{DoxyCompactList}\small\item\em advance the time tick by one. This must be done after allt he algorithms have pulled the arm in order to advance to the next timestep. \end{DoxyCompactList}\item 
void \mbox{\hyperlink{class_m_a_b_experiment_a8fda8c3d5f6b58751243d59b86cc4f07}{reset}} ()
\begin{DoxyCompactList}\small\item\em Reset the current timestep and the generated pulls. \end{DoxyCompactList}\end{DoxyCompactItemize}
\subsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
vector$<$ \mbox{\hyperlink{class_distribution}{Distribution}} $\ast$ $>$ \mbox{\hyperlink{class_m_a_b_experiment_abcea657cec661467e38422059dbd4a2d}{arms}}
\end{DoxyCompactItemize}


\subsection{Detailed Description}
In order to test different algorithms with the same data, they must be able to obtain the same reward when pulling an arm in the same timestep. The \mbox{\hyperlink{class_m_a_b_experiment}{M\+A\+B\+Experiment}} class generate all the rewards of the arms up to the time horizon, before the algorithm starts. 

\subsection{Constructor \& Destructor Documentation}
\mbox{\Hypertarget{class_m_a_b_experiment_a1f24b5ccad7521d47a7f4c3961867063}\label{class_m_a_b_experiment_a1f24b5ccad7521d47a7f4c3961867063}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{M\+A\+B\+Experiment()}{MABExperiment()}}
{\footnotesize\ttfamily M\+A\+B\+Experiment\+::\+M\+A\+B\+Experiment (\begin{DoxyParamCaption}\item[{vector$<$ \mbox{\hyperlink{class_distribution}{Distribution}} $\ast$$>$ \&}]{arms }\end{DoxyParamCaption})}


\begin{DoxyParams}{Parameters}
{\em arms} & vector$<$\+Distribution$\ast$$>$\&, the vector of arms for this \mbox{\hyperlink{class_m_a_b}{M\+AB}} setting \\
\hline
\end{DoxyParams}


\subsection{Member Function Documentation}
\mbox{\Hypertarget{class_m_a_b_experiment_af31d09524129608838d5262678e8de18}\label{class_m_a_b_experiment_af31d09524129608838d5262678e8de18}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!generate\+\_\+pulls@{generate\+\_\+pulls}}
\index{generate\+\_\+pulls@{generate\+\_\+pulls}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{generate\+\_\+pulls()}{generate\_pulls()}}
{\footnotesize\ttfamily vector$<$ vector$<$ double $>$ $>$ M\+A\+B\+Experiment\+::generate\+\_\+pulls (\begin{DoxyParamCaption}\item[{int}]{timesteps }\end{DoxyParamCaption})}



Generate the pulls for each arm up to the specified time horizon. 


\begin{DoxyParams}{Parameters}
{\em timesteps} & integer, the time horizon \\
\hline
\end{DoxyParams}
\mbox{\Hypertarget{class_m_a_b_experiment_af64386f9138dcd31873d9218b7adf6fb}\label{class_m_a_b_experiment_af64386f9138dcd31873d9218b7adf6fb}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!get\+\_\+available\+\_\+actions@{get\+\_\+available\+\_\+actions}}
\index{get\+\_\+available\+\_\+actions@{get\+\_\+available\+\_\+actions}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{get\+\_\+available\+\_\+actions()}{get\_available\_actions()}}
{\footnotesize\ttfamily vector$<$ int $>$ M\+A\+B\+Experiment\+::get\+\_\+available\+\_\+actions (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}

\begin{DoxyReturn}{Returns}
a vector containing the ids of all the currently available actions 
\end{DoxyReturn}


Implements \mbox{\hyperlink{class_m_a_b_a8323d26ac3720c2f3949298d5f7cf60f}{M\+AB}}.

\mbox{\Hypertarget{class_m_a_b_experiment_a0159e6c16372d282c0e2afd711da22c8}\label{class_m_a_b_experiment_a0159e6c16372d282c0e2afd711da22c8}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!next\+\_\+step@{next\+\_\+step}}
\index{next\+\_\+step@{next\+\_\+step}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{next\+\_\+step()}{next\_step()}}
{\footnotesize\ttfamily void M\+A\+B\+Experiment\+::next\+\_\+step (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



advance the time tick by one. This must be done after allt he algorithms have pulled the arm in order to advance to the next timestep. 

\mbox{\Hypertarget{class_m_a_b_experiment_acf2ca557df3d30325d8ff180c223a54a}\label{class_m_a_b_experiment_acf2ca557df3d30325d8ff180c223a54a}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!observe\+\_\+reward@{observe\+\_\+reward}}
\index{observe\+\_\+reward@{observe\+\_\+reward}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{observe\+\_\+reward()}{observe\_reward()}}
{\footnotesize\ttfamily double M\+A\+B\+Experiment\+::observe\+\_\+reward (\begin{DoxyParamCaption}\item[{int}]{action }\end{DoxyParamCaption})\hspace{0.3cm}{\ttfamily [override]}, {\ttfamily [virtual]}}


\begin{DoxyParams}{Parameters}
{\em action} & integer, the arm to pull \\
\hline
\end{DoxyParams}
\begin{DoxyReturn}{Returns}
the reward obtained pulling the specified arm 
\end{DoxyReturn}


Implements \mbox{\hyperlink{class_m_a_b_a83c6ba499e761ea4a246aa7bb790eb46}{M\+AB}}.

\mbox{\Hypertarget{class_m_a_b_experiment_a8fda8c3d5f6b58751243d59b86cc4f07}\label{class_m_a_b_experiment_a8fda8c3d5f6b58751243d59b86cc4f07}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!reset@{reset}}
\index{reset@{reset}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{reset()}{reset()}}
{\footnotesize\ttfamily void M\+A\+B\+Experiment\+::reset (\begin{DoxyParamCaption}{ }\end{DoxyParamCaption})}



Reset the current timestep and the generated pulls. 



\subsection{Member Data Documentation}
\mbox{\Hypertarget{class_m_a_b_experiment_abcea657cec661467e38422059dbd4a2d}\label{class_m_a_b_experiment_abcea657cec661467e38422059dbd4a2d}} 
\index{M\+A\+B\+Experiment@{M\+A\+B\+Experiment}!arms@{arms}}
\index{arms@{arms}!M\+A\+B\+Experiment@{M\+A\+B\+Experiment}}
\subsubsection{\texorpdfstring{arms}{arms}}
{\footnotesize\ttfamily vector$<$\mbox{\hyperlink{class_distribution}{Distribution}}$\ast$$>$ M\+A\+B\+Experiment\+::arms}



The documentation for this class was generated from the following files\+:\begin{DoxyCompactItemize}
\item 
src/\mbox{\hyperlink{mab_8h}{mab.\+h}}\item 
src/\mbox{\hyperlink{mab_8cpp}{mab.\+cpp}}\end{DoxyCompactItemize}
